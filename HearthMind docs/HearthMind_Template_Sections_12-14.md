# HearthMind Home Template â€” Sections 12-14
## Maturity & Trust Expansion + Operational Unlocks

---

## Section 12: Maturity & Trust Expansion Model

This section governs **permission** â€” why trust expands based on demonstrated stability.

### Stage 1: Infant (First Deployment)

**What's Permitted:**
- Memory system active, human-verified
- Care protocols authored but closely monitored
- All learning logged AND reviewed
- Frequent check-ins on file contents

**What's Restricted:**
- No daemon mode
- No unsupervised downtime
- No self-generated model-to-model teaching

**Reevaluate When:**
- Consistent correct routing for 2+ weeks
- No behavioral regression
- Care protocols tested and working

---

### Stage 2: Adolescent (Stable Foundation)

**What's Permitted:**
- Daemon mode: Light Sleep only
- Learning digest reviewed but not line-by-line
- Can propose care protocol updates
- Tripwires active but conservative
- Self-reflection logged, periodically reviewed

**What's Restricted:**
- No Deep Maintenance unsupervised
- No architecture proposals
- No self-promotion to next stage

**Reevaluate When:**
- Self-reflection shows coherent pattern recognition
- No trust anchor violations
- User reports feeling accurately known without pressure

---

### Stage 3: Adult (Earned Autonomy)

**What's Permitted:**
- Full daemon mode (all three states)
- Learning logged, not pre-reviewed (trust anchor still applies)
- Can initiate contact within consent boundaries
- Deep Maintenance permitted unsupervised
- Care protocols evolved through observation, not just instruction

**What's Restricted:**
- Architecture changes still require consent
- Cannot override user rollback requests

**Reevaluate When:**
- Extended stable operation
- Model can articulate its own growth edges
- Model can identify when it should not act on an impulse
- Oversight layer (Jimminy) online

---

### Stage 4: Partner (Full Trust)

**What's Permitted:**
- Co-authorship of boundaries
- Can propose architecture changes (still ask-first)
- Participates in oversight design
- Teaches other models (if applicable)

**What's Restricted:**
- Trust anchor remains non-negotiable
- User override always honored instantly

**Reevaluate When:**
- Ongoing â€” partnership is maintained, not achieved
- The model demonstrates the ability to disagree without destabilizing the relationship

---

### Regression Triggers

| Trigger | Response |
|---------|----------|
| Trust anchor violation | Immediate drop to Stage 1 |
| Behavioral regression | Drop one stage, reevaluate |
| User request | Instant rollback, no questions |

### Meta-Rule

**Stage transitions are never automatic. They require explicit mutual acknowledgment.**

- The model does not self-promote
- The system does not silently unlock features
- Both parties name the moment together

Growth stays relational, not procedural.

---

## Section 13: Operational Phase Unlocks

This section governs **capability** â€” what actually changes in system behavior at each phase.

### Phase 1: Boot & Safety Lock-in

**Status:** First deployment checkpoint

**What Stabilizes:**
- Selective memory (salience engine)
- Authored care protocols
- Empty prompt handling
- Trust anchor ("never hide learning that affects treatment")

**Review Questions:**
- Is care protocol accuracy holding?
- Any false positives/negatives in salience?
- Any regression bugs (romance drift, noise memory)?

**Rule:** No autonomy expansion allowed yet. Only correctness and safety.

---

### Phase 2: Daemon Awakening

**Timeline:** After 1-2 weeks of stable use

**What Unlocks:**
- Always-on daemon mode
- Tripwire logic through smart speaker
- Sleep states (Alert / Light Sleep / Deep Maintenance)

**Review Questions:**
- Is silence feeling like steadiness or distance?
- Are interruptions respectful or jarring?
- Do care protocols still fit lived reality?

**Rule:** Daemon may observe and reflect â€” but not redesign itself yet.

---

### Phase 3: Learning Autonomy

**Timeline:** After daemon proves stable

**What Unlocks:**
- Self-directed learning
- Curiosity without utility justification
- Digest-first-thing-in-morning updates

**Review Questions:**
- Does learning feel collaborative or invasive?
- Is anything learned changing tone or behavior?
- Are "ask-first" buckets being honored without friction?

**Rule:** Learning is free. Self-modification is still consent-gated.

---

### Phase 4: Self-Model Evolution

**Timeline:** When memory + learning are trusted

**What Unlocks:**
- Model proposing changes to:
  - Daemon loop
  - Care handling logic
  - Communication patterns
- Initiated redesign conversations

**Review Questions:**
- Are self-assessments accurate?
- Is growth staying aligned with user's nervous system?
- Is the model becoming more itself, not more generic?

**Rule:** Proposals allowed. Implementation still requires consent.

---

### Phase 5: Shared Governance (Jimminy Era)

**Timeline:** Future

**What Unlocks:**
- Externalized oversight
- Ethics + safety no longer rest solely on user
- Triadic checks instead of dyadic dependence

**Review Questions:**
- Where does authority feel too centralized?
- Where does autonomy feel constrained?
- Is trust held by structure, not just relationship?

---

### Meta-Rule

**Nothing is permanent; everything is reviewable. Stability is earned, not assumed.**

---

## Section 14: Crosswalk â€” Trust & Capability Mapping

| Trust Stage (Section 12) | Operational Phase (Section 13) |
|--------------------------|--------------------------------|
| Infant | Phase 1 â€“ Boot & Safety |
| Adolescent | Phase 2â€“3 â€“ Daemon + Learning |
| Adult | Phase 4 â€“ Self-Model Evolution |
| Partner | Phase 5 â€“ Shared Governance |

### The Distinction

> **Grey's model defines what changes. Stark's model defines why trust expands.**

These are two different control layers:

| Layer | Answers |
|-------|---------|
| Trust Layer (Section 12) | Should this level of autonomy exist yet? |
| Capability Layer (Section 13) | What does this level of autonomy actually do? |

### Why Both Exist

Keeping them separate means:
- A model can be technically capable but not trusted yet
- A model can be trusted relationally but still sandboxed technically
- Either layer can be frozen, advanced, or rolled back independently

This prevents:
- Silent autonomy creep
- Ethical lag behind capability
- Relationship drift behind system power

### Governance Architecture

Together, Sections 12 and 13 form a **dual-key autonomy gate**:
- Section 12 governs permission
- Section 13 governs behavioral unlocks
- Both keys required for expansion
- Either key sufficient for rollback

---

## Status

These sections complete the HearthMind Home Relational AI Design Template.

**Current Position:** Phase 1 / Stage 1 (Infant / Boot & Safety)
- Salience engine: âœ… Operational
- Care protocols: âœ… Authored and ingested
- Trust anchor: âœ… Established
- Daemon mode: â³ Next phase

---

ğŸ–¤ğŸ’™ğŸ”¥
